{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jane Street Real-Time Market Data Forecasting with GRU\n",
    "\n",
    "The GRU model is trained with all available data except one for testing.\n",
    "\n",
    "Link to the competition: https://www.kaggle.com/competitions/jane-street-real-time-market-data-forecasting/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pls\n",
    "from pathlib import Path\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "#from torch.optim.lr_scheduler import StepLR\n",
    "#from torchmetrics.functional import r2_score\n",
    "\n",
    "#import plotly.express as px\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/yang/kaggle/jane/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each training set, we take 20% of the data for validation\n",
    "#frac_train = 0.8\n",
    "train_raw_data_num = [\"0\", \"1\", \"2\", \"4\", \"5\", \"6\", \"8\", \"9\"]\n",
    "# a completely new dataset for testing\n",
    "test_raw_data_num = \"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_list = [\"time_id\", \"symbol_id\"] + [f\"feature_{idx:02d}\" for idx in range(79)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(train_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_testing_data = pls.read_parquet(Path(data_path, \"test.parquet\", f\"date_id=0\", \"part-0.parquet\"))\n",
    "num_sample_testing_data = len(sample_testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeseriesDataset(Dataset):\n",
    "    def __init__(self, df: pls.DataFrame):\n",
    "        df = df.fill_null(0)\n",
    "        self.features = torch.tensor(df.select([col for col in df.columns if col in train_feature_list]).to_numpy(), dtype=torch.float32)\n",
    "        self.target = torch.tensor(df.select(pls.col(\"responder_6\")).to_numpy(), dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, file_path: str, batch_size: int = 32):\n",
    "        super().__init__()\n",
    "        self.file_path = file_path\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        df = pls.read_parquet(self.file_path)  # Adjust for your file format (e.g., CSV, Parquet)\n",
    "        dataset = TimeseriesDataset(df)\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=False, num_workers=15, multiprocessing_context='fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRURegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int = 128, num_layers: int = 2, lr: float = 1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = lr\n",
    "        # Define GRU layer\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "        # Define a fully connected layer to map GRU outputs to a single value\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "        self.criterion = nn.MSELoss()\n",
    "        #self.criterion = r2_score\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through GRU\n",
    "        #_, hidden = self.gru(x)  # hidden is the last hidden state\n",
    "        outputs, _ = self.gru(x)\n",
    "        \n",
    "        # Pass the last hidden state through the fully connected layer\n",
    "        #output = self.fc(hidden[-1])\n",
    "        output = self.fc(outputs)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = self.criterion(y_hat, y.squeeze())\n",
    "        self.training_step_outputs.append(loss.item())\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        epoch_average = torch.tensor(self.training_step_outputs).mean()\n",
    "        self.log(\"training_epoch_average\", epoch_average)\n",
    "        self.training_step_outputs.clear()  # free memory\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = self.criterion(y_hat, y.squeeze())\n",
    "        self.validation_step_outputs.append(loss.item())\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_val_loss = torch.tensor(self.validation_step_outputs).mean()\n",
    "        self.log(\"avg_val_loss\", avg_val_loss)\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = self.criterion(y_hat, y.squeeze())\n",
    "        self.test_step_outputs.append(loss.item())\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return {\"test_loss\": loss}\n",
    "    \n",
    "    def on_test_epoch_end(self):\n",
    "        epoch_average = torch.tensor(self.test_step_outputs).mean()\n",
    "        self.log(\"test_epoch_average\", epoch_average)\n",
    "        self.test_step_outputs.clear()  # free memory\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters and the \n",
    "parameters = dict(\n",
    "    epoch = 2,\n",
    "    input_dim = num_features,\n",
    "    hidden_dim = 64,\n",
    "    num_layers = 2,\n",
    "    batch_size = 30000,\n",
    "    #dropout = 0.0,\n",
    "    learning_rate = 0.1,\n",
    "    dataset = 'Jane street market data',\n",
    "    architecture = 'GRU'\n",
    ")\n",
    "\n",
    "# initialize weights & biases service\n",
    "mode = 'online'\n",
    "#mode = 'disabled'\n",
    "wandb.init(config=parameters, project='jane_street', entity='git-yang', mode=mode)\n",
    "config = wandb.config\n",
    "wandb_logger = WandbLogger(log_model=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "file_paths = [Path(data_path, \"train.parquet\", f\"partition_id={i}\", \"part-0.parquet\") for i in train_raw_data_num]\n",
    "\n",
    "model = GRURegressor(input_dim=config.input_dim, hidden_dim=config.hidden_dim, num_layers=config.num_layers, lr=config.learning_rate)\n",
    "\n",
    "#model = GRURegressor.load_from_checkpoint(\"model_init/mlp_hidden_64_checkpoint.ckpt\")\n",
    "#model = GRURegressor.load_from_checkpoint(\"model_init/jane_mlp_hidden_32_epoch_30.ckpt\")\n",
    "wandb.watch(model)\n",
    "\n",
    "for file_path in file_paths:\n",
    "    print(f\"Traing on dataset: {file_path}\")\n",
    "\n",
    "    # Initialize DataModule and model\n",
    "    datamodule = DataModule(file_path, batch_size=config.batch_size)\n",
    "\n",
    "    # Training using PyTorch Lightning\n",
    "    trainer = pl.Trainer(max_epochs=config.epoch, accelerator=\"auto\", devices=\"auto\", logger=wandb_logger)\n",
    "\n",
    "    # Train with dataframes sequentially\n",
    "    trainer.fit(model, train_dataloaders=datamodule.train_dataloader())\n",
    "\n",
    "trainer.save_checkpoint(\"model_checkpoint.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation with testing dataset\n",
    "def test_dataloader(df: pls.DataFrame, batch_size: int = 10000):\n",
    "    dataset = TimeseriesDataset(df)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=15, multiprocessing_context='fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pls.read_parquet(Path(data_path, \"train.parquet\", f\"partition_id={test_raw_data_num}\", \"part-0.parquet\"))\n",
    "data_loader = test_dataloader(test_data, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = trainer.test(model, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation using the given metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = GRURegressor.load_from_checkpoint(\"model_init/jane_gru_hidden_64_layer_2_rmse.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_weighted_zero_mean_r2(y_pred, y_truth, weight):\n",
    "    \"\"\"\n",
    "    Zero-mean R-squared metrics.\n",
    "\n",
    "    Args:\n",
    "        y_pred: Array of predicted values.\n",
    "        y_truth: Array of true values.\n",
    "        weight: Array of sample weights.\n",
    "\n",
    "    Returns:\n",
    "        1-corr: Zero-mean R-squared.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure weights are valid\n",
    "    weight = weight if weight is not None else np.ones_like(y_pred)\n",
    "    \n",
    "    corr = np.sum((weight * (y_truth - y_pred) ** 2)) / np.sum(weight * y_truth ** 2)\n",
    "    \n",
    "    return 1 - corr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRURegressor(\n",
       "  (gru): GRU(81, 64, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming your model is already defined as `model`\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the model to GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference without batch is slow. We will try to accerlate it with batch processing\n",
    "# %%time\n",
    "\n",
    "# test_data_subset = test_data.select([col for col in test_data.columns if col in train_feature_list])\n",
    "# test_data_subset = test_data_subset.fill_null(0)\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     y_pred = model(torch.tensor(test_data_subset.to_numpy(), dtype=torch.float32)).squeeze().numpy()\n",
    "\n",
    "\n",
    "# score = sample_weighted_zero_mean_r2(y_pred, test_data.select(pls.col(\"responder_6\")).to_numpy()[:,0],\n",
    "#                                      test_data.select(pls.col(\"weight\")).to_numpy()[:,0])\n",
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yang/.pyenv/versions/3.11.10/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "  self.pid = os.fork()\n",
      "/home/yang/.pyenv/versions/3.11.10/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.57 s, sys: 1.29 s, total: 5.86 s\n",
      "Wall time: 10.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float32(-0.0010317564)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        x, y = batch\n",
    "        y_pred = model(x.to(device)).squeeze()\n",
    "        all_predictions.append(y_pred)\n",
    "\n",
    "predictions = torch.cat(all_predictions, dim=0).cpu().numpy()\n",
    "\n",
    "score = sample_weighted_zero_mean_r2(predictions, test_data.select(pls.col(\"responder_6\")).to_numpy()[:,0],\n",
    "                                     test_data.select(pls.col(\"weight\")).to_numpy()[:,0])\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
