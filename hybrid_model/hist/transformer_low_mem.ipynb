{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jane Street Real-Time Market Data Forecasting with GRU\n",
    "\n",
    "The GRU model is trained with all available data except one for testing.\n",
    "\n",
    "Link to the competition: https://www.kaggle.com/competitions/jane-street-real-time-market-data-forecasting/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import polars as pls\n",
    "from pathlib import Path\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "#from torch.optim.lr_scheduler import StepLR\n",
    "#from torchmetrics.functional import r2_score\n",
    "\n",
    "#import plotly.express as px\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/yang/kaggle/jane/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each training set, we take 20% of the data for validation\n",
    "#frac_train = 0.8\n",
    "train_raw_data_num = [\"0\", \"1\", \"2\", \"4\", \"5\", \"6\", \"8\", \"9\"]\n",
    "# a completely new dataset for testing\n",
    "test_raw_data_num = \"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_list = [\"time_id\", \"symbol_id\"] + [f\"feature_{idx:02d}\" for idx in range(79)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(train_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_testing_data = pls.read_parquet(Path(data_path, \"test.parquet\", f\"date_id=0\", \"part-0.parquet\"))\n",
    "num_sample_testing_data = len(sample_testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeseriesDataset(Dataset):\n",
    "    def __init__(self, df: pls.DataFrame):\n",
    "        df = df.fill_null(0)\n",
    "        self.features = torch.tensor(df.select([col for col in df.columns if col in train_feature_list]).to_numpy(), dtype=torch.float32)\n",
    "        self.target = torch.tensor(df.select(pls.col(\"responder_6\")).to_numpy(), dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, file_path: str, batch_size: int = 32):\n",
    "        super().__init__()\n",
    "        self.file_path = file_path\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        df = pls.read_parquet(self.file_path)  # Adjust for your file format (e.g., CSV, Parquet)\n",
    "        dataset = TimeseriesDataset(df)\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=False, num_workers=15, multiprocessing_context='fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :].to(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim: int, d_model=128, nhead=4, num_layers=2, lr: float = 1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = lr\n",
    "\n",
    "        self.input_projection = nn.Linear(input_dim, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(d_model, 1)\n",
    "\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "        self.criterion = nn.MSELoss()\n",
    "        #self.criterion = r2_score\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 2:  # Handle single sequence case (no batch dimension)\n",
    "            x = x.unsqueeze(0)  # Add batch dimension: (1, sequence_length, features)\n",
    "        # x: (batch_size, seq_len, input_dim)\n",
    "        x = self.input_projection(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        # Transformer expects input of shape (seq_len, batch_size, d_model)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = self.transformer(x)\n",
    "        # Use the output of the last time step\n",
    "        x = x[-1]\n",
    "        return self.fc(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = self.criterion(y_hat, y.squeeze())\n",
    "        self.training_step_outputs.append(loss.item())\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        epoch_average = torch.tensor(self.training_step_outputs).mean()\n",
    "        self.log(\"training_epoch_average\", epoch_average)\n",
    "        self.training_step_outputs.clear()  # free memory\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = self.criterion(y_hat, y.squeeze())\n",
    "        self.validation_step_outputs.append(loss.item())\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_val_loss = torch.tensor(self.validation_step_outputs).mean()\n",
    "        self.log(\"avg_val_loss\", avg_val_loss)\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = self.criterion(y_hat, y.squeeze())\n",
    "        self.test_step_outputs.append(loss.item())\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return {\"test_loss\": loss}\n",
    "    \n",
    "    def on_test_epoch_end(self):\n",
    "        epoch_average = torch.tensor(self.test_step_outputs).mean()\n",
    "        self.log(\"test_epoch_average\", epoch_average)\n",
    "        self.test_step_outputs.clear()  # free memory\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgit-yang\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/yang/kaggle/jane/sandbox/hybrid_model/wandb/run-20241215_122208-vhxzt69c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/git-yang/jane_street/runs/vhxzt69c' target=\"_blank\">sleek-snowflake-36</a></strong> to <a href='https://wandb.ai/git-yang/jane_street' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/git-yang/jane_street' target=\"_blank\">https://wandb.ai/git-yang/jane_street</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/git-yang/jane_street/runs/vhxzt69c' target=\"_blank\">https://wandb.ai/git-yang/jane_street/runs/vhxzt69c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define hyperparameters and the \n",
    "parameters = dict(\n",
    "    epoch = 20,\n",
    "    input_dim = num_features,\n",
    "    d_model = 128,\n",
    "    nhead = 4,\n",
    "    num_layers = 2,\n",
    "    batch_size = 1024,\n",
    "    #dropout = 0.0,\n",
    "    learning_rate = 0.05,\n",
    "    dataset = 'Jane street market data',\n",
    "    architecture = 'GRU'\n",
    ")\n",
    "\n",
    "# initialize weights & biases service\n",
    "mode = 'online'\n",
    "#mode = 'disabled'\n",
    "wandb.init(config=parameters, project='jane_street', entity='git-yang', mode=mode)\n",
    "config = wandb.config\n",
    "wandb_logger = WandbLogger(log_model=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing on dataset: /home/yang/kaggle/jane/data/train.parquet/partition_id=0/part-0.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yang/.pyenv/versions/3.11.10/envs/ml/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/yang/.pyenv/versions/3.11.10/envs/ml/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | gru       | GRU     | 180 K  | train\n",
      "1 | fc        | Linear  | 129    | train\n",
      "2 | criterion | MSELoss | 0      | train\n",
      "----------------------------------------------\n",
      "180 K     Trainable params\n",
      "0         Non-trainable params\n",
      "180 K     Total params\n",
      "0.721     Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/yang/.pyenv/versions/3.11.10/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/195 [00:00<?, ?it/s, v_num=t69c]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yang/.pyenv/versions/3.11.10/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:   0%|          | 0/195 [00:00<?, ?it/s, v_num=t69c]               "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yang/.pyenv/versions/3.11.10/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:   0%|          | 0/195 [00:00<?, ?it/s, v_num=t69c]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yang/.pyenv/versions/3.11.10/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 195/195 [00:08<00:00, 22.73it/s, v_num=t69c]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 195/195 [00:08<00:00, 22.08it/s, v_num=t69c]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traing on dataset: /home/yang/kaggle/jane/data/train.parquet/partition_id=1/part-0.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yang/.pyenv/versions/3.11.10/envs/ml/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/yang/.pyenv/versions/3.11.10/envs/ml/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory ./lightning_logs/vhxzt69c/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | gru       | GRU     | 180 K  | train\n",
      "1 | fc        | Linear  | 129    | train\n",
      "2 | criterion | MSELoss | 0      | train\n",
      "----------------------------------------------\n",
      "180 K     Trainable params\n",
      "0         Non-trainable params\n",
      "180 K     Total params\n",
      "0.721     Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 281/281 [00:09<00:00, 28.67it/s, v_num=t69c]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 281/281 [00:10<00:00, 27.81it/s, v_num=t69c]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traing on dataset: /home/yang/kaggle/jane/data/train.parquet/partition_id=2/part-0.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | gru       | GRU     | 180 K  | train\n",
      "1 | fc        | Linear  | 129    | train\n",
      "2 | criterion | MSELoss | 0      | train\n",
      "----------------------------------------------\n",
      "180 K     Trainable params\n",
      "0         Non-trainable params\n",
      "180 K     Total params\n",
      "0.721     Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 304/304 [00:13<00:00, 22.66it/s, v_num=t69c]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 304/304 [00:13<00:00, 22.21it/s, v_num=t69c]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traing on dataset: /home/yang/kaggle/jane/data/train.parquet/partition_id=4/part-0.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | gru       | GRU     | 180 K  | train\n",
      "1 | fc        | Linear  | 129    | train\n",
      "2 | criterion | MSELoss | 0      | train\n",
      "----------------------------------------------\n",
      "180 K     Trainable params\n",
      "0         Non-trainable params\n",
      "180 K     Total params\n",
      "0.721     Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 503/503 [00:17<00:00, 28.11it/s, v_num=t69c]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 503/503 [00:18<00:00, 27.66it/s, v_num=t69c]\n",
      "Traing on dataset: /home/yang/kaggle/jane/data/train.parquet/partition_id=5/part-0.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | gru       | GRU     | 180 K  | train\n",
      "1 | fc        | Linear  | 129    | train\n",
      "2 | criterion | MSELoss | 0      | train\n",
      "----------------------------------------------\n",
      "180 K     Trainable params\n",
      "0         Non-trainable params\n",
      "180 K     Total params\n",
      "0.721     Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 535/535 [00:19<00:00, 27.05it/s, v_num=t69c]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 535/535 [00:20<00:00, 26.68it/s, v_num=t69c]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traing on dataset: /home/yang/kaggle/jane/data/train.parquet/partition_id=6/part-0.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | gru       | GRU     | 180 K  | train\n",
      "1 | fc        | Linear  | 129    | train\n",
      "2 | criterion | MSELoss | 0      | train\n",
      "----------------------------------------------\n",
      "180 K     Trainable params\n",
      "0         Non-trainable params\n",
      "180 K     Total params\n",
      "0.721     Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 621/621 [00:24<00:00, 25.44it/s, v_num=t69c]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 621/621 [00:24<00:00, 25.15it/s, v_num=t69c]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing on dataset: /home/yang/kaggle/jane/data/train.parquet/partition_id=8/part-0.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | gru       | GRU     | 180 K  | train\n",
      "1 | fc        | Linear  | 129    | train\n",
      "2 | criterion | MSELoss | 0      | train\n",
      "----------------------------------------------\n",
      "180 K     Trainable params\n",
      "0         Non-trainable params\n",
      "180 K     Total params\n",
      "0.721     Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 615/615 [00:24<00:00, 25.51it/s, v_num=t69c]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 615/615 [00:24<00:00, 25.23it/s, v_num=t69c]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing on dataset: /home/yang/kaggle/jane/data/train.parquet/partition_id=9/part-0.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | gru       | GRU     | 180 K  | train\n",
      "1 | fc        | Linear  | 129    | train\n",
      "2 | criterion | MSELoss | 0      | train\n",
      "----------------------------------------------\n",
      "180 K     Trainable params\n",
      "0         Non-trainable params\n",
      "180 K     Total params\n",
      "0.721     Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 628/628 [00:25<00:00, 24.73it/s, v_num=t69c]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 628/628 [00:25<00:00, 24.45it/s, v_num=t69c]\n",
      "CPU times: user 42min 46s, sys: 7min 21s, total: 50min 8s\n",
      "Wall time: 50min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_paths = [Path(data_path, \"train.parquet\", f\"partition_id={i}\", \"part-0.parquet\") for i in train_raw_data_num]\n",
    "\n",
    "model = TransformerRegressor(input_dim=config.input_dim, hidden_dim=config.hidden_dim, num_layers=config.num_layers, lr=config.learning_rate)\n",
    "\n",
    "#model = TransformerRegressor.load_from_checkpoint(\"model_init/mlp_hidden_64_checkpoint.ckpt\")\n",
    "#model = TransformerRegressor.load_from_checkpoint(\"model_init/jane_mlp_hidden_32_epoch_30.ckpt\")\n",
    "wandb.watch(model)\n",
    "\n",
    "for file_path in file_paths:\n",
    "    print(f\"Traing on dataset: {file_path}\")\n",
    "\n",
    "    # Initialize DataModule and model\n",
    "    datamodule = DataModule(file_path, batch_size=config.batch_size)\n",
    "\n",
    "    # Training using PyTorch Lightning\n",
    "    trainer = pl.Trainer(max_epochs=config.epoch, accelerator=\"auto\", devices=\"auto\", logger=wandb_logger)\n",
    "\n",
    "    # Train with dataframes sequentially\n",
    "    trainer.fit(model, train_dataloaders=datamodule.train_dataloader())\n",
    "\n",
    "trainer.save_checkpoint(\"model_checkpoint.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation with testing dataset\n",
    "def test_dataloader(df: pls.DataFrame, batch_size: int = 10000):\n",
    "    dataset = TimeseriesDataset(df)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=15, multiprocessing_context='fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pls.read_parquet(Path(data_path, \"train.parquet\", f\"partition_id={test_raw_data_num}\", \"part-0.parquet\"))\n",
    "data_loader = test_dataloader(test_data, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 634/634 [00:13<00:00, 47.29it/s]    \n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   test_epoch_average        0.699215292930603\n",
      "        test_loss           0.6991668343544006\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "test_results = trainer.test(model, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▂▄▆▃▄▁▂▂▄▇▁▂▅▅▇▂▄▅▅▅█▃▄▅▆▇█▁▂▃▄▆▇▇█▃▅▅▆█</td></tr><tr><td>test_epoch_average</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>▃▄▄▄▅▃▅▃█▄▅▅▃▇▃▄▅▃▃▃▂▁▃▂▄▃▆▇▄▄▃▂▅▃▃▂▃▂▄▂</td></tr><tr><td>trainer/global_step</td><td>▃▃▁▂▃▃▁▂▃▄▁▂▂▄▄▂▂▃▄▄▇▇▁▆█▄▅▆▆▇▂▃▄▄▄▅▅▆▇█</td></tr><tr><td>training_epoch_average</td><td>▃▃▄▄▅▅▅▅▅▅▇▇▇███▅▅▅▅▄▅▅▅▅▅▅▅▅▃▃▃▃▃▃▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>test_epoch_average</td><td>0.69922</td></tr><tr><td>test_loss</td><td>0.69917</td></tr><tr><td>train_loss</td><td>0.66779</td></tr><tr><td>trainer/global_step</td><td>12560</td></tr><tr><td>training_epoch_average</td><td>0.7319</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sleek-snowflake-36</strong> at: <a href='https://wandb.ai/git-yang/jane_street/runs/vhxzt69c' target=\"_blank\">https://wandb.ai/git-yang/jane_street/runs/vhxzt69c</a><br/> View project at: <a href='https://wandb.ai/git-yang/jane_street' target=\"_blank\">https://wandb.ai/git-yang/jane_street</a><br/>Synced 5 W&B file(s), 0 media file(s), 322 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241215_122208-vhxzt69c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation using the given metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = GRURegressor.load_from_checkpoint(\"model_init/jane_gru_hidden_64_layer_2_rmse.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_weighted_zero_mean_r2(y_pred, y_truth, weight):\n",
    "    \"\"\"\n",
    "    Zero-mean R-squared metrics.\n",
    "\n",
    "    Args:\n",
    "        y_pred: Array of predicted values.\n",
    "        y_truth: Array of true values.\n",
    "        weight: Array of sample weights.\n",
    "\n",
    "    Returns:\n",
    "        1-corr: Zero-mean R-squared.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure weights are valid\n",
    "    weight = weight if weight is not None else np.ones_like(y_pred)\n",
    "    \n",
    "    corr = np.sum((weight * (y_truth - y_pred) ** 2)) / np.sum(weight * y_truth ** 2)\n",
    "    \n",
    "    return 1 - corr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your model is already defined as `model`\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRURegressor(\n",
       "  (gru): GRU(81, 64, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the model to GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference without batch is slow. We will try to accerlate it with batch processing\n",
    "# %%time\n",
    "\n",
    "# test_data_subset = test_data.select([col for col in test_data.columns if col in train_feature_list])\n",
    "# test_data_subset = test_data_subset.fill_null(0)\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     y_pred = model(torch.tensor(test_data_subset.to_numpy(), dtype=torch.float32)).squeeze().numpy()\n",
    "\n",
    "\n",
    "# score = sample_weighted_zero_mean_r2(y_pred, test_data.select(pls.col(\"responder_6\")).to_numpy()[:,0],\n",
    "#                                      test_data.select(pls.col(\"weight\")).to_numpy()[:,0])\n",
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.92 s, sys: 3.48 s, total: 8.4 s\n",
      "Wall time: 11.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float32(-0.0010317564)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        x, y = batch\n",
    "        y_pred = model(x.to(device)).squeeze()\n",
    "        all_predictions.append(y_pred)\n",
    "\n",
    "predictions = torch.cat(all_predictions, dim=0).cpu().numpy()\n",
    "\n",
    "score = sample_weighted_zero_mean_r2(predictions, test_data.select(pls.col(\"responder_6\")).to_numpy()[:,0],\n",
    "                                     test_data.select(pls.col(\"weight\")).to_numpy()[:,0])\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
