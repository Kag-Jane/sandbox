{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jane Street Real-Time Market Data Forecasting with MLP\n",
    "\n",
    "The MLP model is trained with all available data except one for testing.\n",
    "\n",
    "Link to the competition: https://www.kaggle.com/competitions/jane-street-real-time-market-data-forecasting/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pls\n",
    "from pathlib import Path\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "#from torch.optim.lr_scheduler import StepLR\n",
    "from torchmetrics.functional import r2_score\n",
    "\n",
    "#import plotly.express as px\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/yang/kaggle/jane/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each training set, we take 20% of the data for validation\n",
    "#frac_train = 0.8\n",
    "train_raw_data_num = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "# a completely new dataset for testing\n",
    "test_raw_data_num = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_list = [\"time_id\", \"symbol_id\"] + [f\"feature_{idx:02d}\" for idx in range(79)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(train_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_testing_data = pls.read_parquet(Path(data_path, \"test.parquet\", f\"date_id=0\", \"part-0.parquet\"))\n",
    "num_sample_testing_data = len(sample_testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeseriesDataset(Dataset):\n",
    "    def __init__(self, df: pls.DataFrame):\n",
    "        df = df.fill_null(0)\n",
    "        self.features = torch.tensor(df.select([col for col in df.columns if col in train_feature_list]).to_numpy(), dtype=torch.float32)\n",
    "        self.target = torch.tensor(df.select(pls.col(\"responder_6\")).to_numpy(), dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, file_path: str, batch_size: int = 32, shuffle: bool = True):\n",
    "        super().__init__()\n",
    "        self.file_path = file_path\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        df = pls.read_parquet(self.file_path)  # Adjust for your file format (e.g., CSV, Parquet)\n",
    "        dataset = TimeseriesDataset(df)\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=self.shuffle, num_workers=15, multiprocessing_context='fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int = 128, lr: float = 1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = lr\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "        self.criterion = nn.MSELoss()\n",
    "        #self.criterion = r2_score\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = self.criterion(y_hat, y.squeeze())\n",
    "        self.training_step_outputs.append(loss.item())\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        epoch_average = torch.tensor(self.training_step_outputs).mean()\n",
    "        self.log(\"training_epoch_average\", epoch_average)\n",
    "        self.training_step_outputs.clear()  # free memory\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = self.criterion(y_hat, y.squeeze())\n",
    "        self.validation_step_outputs.append(loss.item())\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_val_loss = torch.tensor(self.validation_step_outputs).mean()\n",
    "        self.log(\"avg_val_loss\", avg_val_loss)\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x).squeeze()\n",
    "        loss = self.criterion(y_hat, y.squeeze())\n",
    "        self.test_step_outputs.append(loss.item())\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return {\"test_loss\": loss}\n",
    "    \n",
    "    def on_test_epoch_end(self):\n",
    "        epoch_average = torch.tensor(self.test_step_outputs).mean()\n",
    "        self.log(\"test_epoch_average\", epoch_average)\n",
    "        self.test_step_outputs.clear()  # free memory\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgit-yang\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/yang/kaggle/jane/sandbox/hybrid_model/wandb/run-20241223_210652-d8utdrhm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/git-yang/jane_street/runs/d8utdrhm' target=\"_blank\">good-puddle-48</a></strong> to <a href='https://wandb.ai/git-yang/jane_street' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/git-yang/jane_street' target=\"_blank\">https://wandb.ai/git-yang/jane_street</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/git-yang/jane_street/runs/d8utdrhm' target=\"_blank\">https://wandb.ai/git-yang/jane_street/runs/d8utdrhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define hyperparameters\n",
    "parameters = dict(\n",
    "    epoch =  25,\n",
    "    input_dim = num_features,\n",
    "    hidden_dim = 256,\n",
    "    batch_size = 15000,\n",
    "    #dropout = 0.0,\n",
    "    learning_rate = 1e-5,\n",
    "    dataset = 'Jane street market data',\n",
    "    architecture = 'MLP'\n",
    ")\n",
    "\n",
    "# initialize weights & biases service\n",
    "mode = 'online'\n",
    "#mode = 'disabled'\n",
    "wandb.init(config=parameters, project='jane_street', entity='git-yang', mode=mode)\n",
    "config = wandb.config\n",
    "wandb_logger = WandbLogger(log_model=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing on dataset: /home/yang/kaggle/jane/data/train.parquet/partition_id=0/part-0.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yang/.pyenv/versions/3.11.10/envs/ml/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/yang/.pyenv/versions/3.11.10/envs/ml/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | model     | Sequential | 87.0 K | train\n",
      "1 | criterion | MSELoss    | 0      | train\n",
      "-------------------------------------------------\n",
      "87.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "87.0 K    Total params\n",
      "0.348     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/yang/.pyenv/versions/3.11.10/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/130 [00:00<?, ?it/s, v_num=drhm]                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yang/.pyenv/versions/3.11.10/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:   0%|          | 0/130 [00:00<?, ?it/s, v_num=drhm]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yang/.pyenv/versions/3.11.10/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:   0%|          | 0/130 [00:00<?, ?it/s, v_num=drhm]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yang/.pyenv/versions/3.11.10/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 130/130 [00:02<00:00, 56.05it/s, v_num=drhm]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 130/130 [00:03<00:00, 38.21it/s, v_num=drhm]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traing on dataset: /home/yang/kaggle/jane/data/train.parquet/partition_id=1/part-0.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yang/.pyenv/versions/3.11.10/envs/ml/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/yang/.pyenv/versions/3.11.10/envs/ml/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory ./lightning_logs/d8utdrhm/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | model     | Sequential | 87.0 K | train\n",
      "1 | criterion | MSELoss    | 0      | train\n",
      "-------------------------------------------------\n",
      "87.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "87.0 K    Total params\n",
      "0.348     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 187/187 [00:04<00:00, 40.53it/s, v_num=drhm]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 187/187 [00:07<00:00, 24.52it/s, v_num=drhm]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traing on dataset: /home/yang/kaggle/jane/data/train.parquet/partition_id=2/part-0.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | model     | Sequential | 87.0 K | train\n",
      "1 | criterion | MSELoss    | 0      | train\n",
      "-------------------------------------------------\n",
      "87.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "87.0 K    Total params\n",
      "0.348     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 203/203 [00:08<00:00, 24.46it/s, v_num=drhm]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 203/203 [00:09<00:00, 20.91it/s, v_num=drhm]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traing on dataset: /home/yang/kaggle/jane/data/train.parquet/partition_id=3/part-0.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | model     | Sequential | 87.0 K | train\n",
      "1 | criterion | MSELoss    | 0      | train\n",
      "-------------------------------------------------\n",
      "87.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "87.0 K    Total params\n",
      "0.348     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 268/268 [00:10<00:00, 24.75it/s, v_num=drhm]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 268/268 [00:11<00:00, 24.17it/s, v_num=drhm]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traing on dataset: /home/yang/kaggle/jane/data/train.parquet/partition_id=4/part-0.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | model     | Sequential | 87.0 K | train\n",
      "1 | criterion | MSELoss    | 0      | train\n",
      "-------------------------------------------------\n",
      "87.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "87.0 K    Total params\n",
      "0.348     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 335/335 [00:12<00:00, 26.59it/s, v_num=drhm]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 335/335 [00:12<00:00, 26.04it/s, v_num=drhm]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traing on dataset: /home/yang/kaggle/jane/data/train.parquet/partition_id=5/part-0.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | model     | Sequential | 87.0 K | train\n",
      "1 | criterion | MSELoss    | 0      | train\n",
      "-------------------------------------------------\n",
      "87.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "87.0 K    Total params\n",
      "0.348     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 357/357 [00:13<00:00, 26.88it/s, v_num=drhm]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 357/357 [00:13<00:00, 26.36it/s, v_num=drhm]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traing on dataset: /home/yang/kaggle/jane/data/train.parquet/partition_id=6/part-0.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | model     | Sequential | 87.0 K | train\n",
      "1 | criterion | MSELoss    | 0      | train\n",
      "-------------------------------------------------\n",
      "87.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "87.0 K    Total params\n",
      "0.348     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 414/414 [00:13<00:00, 31.62it/s, v_num=drhm]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 414/414 [00:13<00:00, 31.00it/s, v_num=drhm]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traing on dataset: /home/yang/kaggle/jane/data/train.parquet/partition_id=7/part-0.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | model     | Sequential | 87.0 K | train\n",
      "1 | criterion | MSELoss    | 0      | train\n",
      "-------------------------------------------------\n",
      "87.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "87.0 K    Total params\n",
      "0.348     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 423/423 [00:16<00:00, 26.19it/s, v_num=drhm]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 423/423 [00:16<00:00, 25.78it/s, v_num=drhm]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing on dataset: /home/yang/kaggle/jane/data/train.parquet/partition_id=8/part-0.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | model     | Sequential | 87.0 K | train\n",
      "1 | criterion | MSELoss    | 0      | train\n",
      "-------------------------------------------------\n",
      "87.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "87.0 K    Total params\n",
      "0.348     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 410/410 [00:15<00:00, 27.21it/s, v_num=drhm]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 410/410 [00:15<00:00, 26.74it/s, v_num=drhm]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing on dataset: /home/yang/kaggle/jane/data/train.parquet/partition_id=9/part-0.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | model     | Sequential | 87.0 K | train\n",
      "1 | criterion | MSELoss    | 0      | train\n",
      "-------------------------------------------------\n",
      "87.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "87.0 K    Total params\n",
      "0.348     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 419/419 [00:17<00:00, 23.38it/s, v_num=drhm]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 419/419 [00:18<00:00, 23.04it/s, v_num=drhm]\n",
      "CPU times: user 25min 59s, sys: 11min 39s, total: 37min 38s\n",
      "Wall time: 53min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_paths = [Path(data_path, \"train.parquet\", f\"partition_id={i}\", \"part-0.parquet\") for i in train_raw_data_num]\n",
    "\n",
    "model = MLPRegressor(input_dim=config.input_dim, hidden_dim=config.hidden_dim, lr=config.learning_rate)\n",
    "\n",
    "#model = MLPRegressor.load_from_checkpoint(\"model_init/mlp_hidden_64_checkpoint.ckpt\")\n",
    "#model = MLPRegressor.load_from_checkpoint(\"model_init/jane_mlp_hidden_32_epoch_30.ckpt\")\n",
    "wandb.watch(model)\n",
    "\n",
    "for file_path in file_paths:\n",
    "    print(f\"Traing on dataset: {file_path}\")\n",
    "\n",
    "    # Initialize DataModule and model\n",
    "    datamodule = DataModule(file_path, batch_size=config.batch_size)\n",
    "\n",
    "    # Training using PyTorch Lightning\n",
    "    trainer = pl.Trainer(max_epochs=config.epoch, accelerator=\"auto\", devices=\"auto\", logger=wandb_logger)\n",
    "\n",
    "    # Train with dataframes sequentially\n",
    "    trainer.fit(model, train_dataloaders=datamodule.train_dataloader())\n",
    "\n",
    "trainer.save_checkpoint(\"model_checkpoint.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation with testing dataset\n",
    "def test_dataloader(df: pls.DataFrame, batch_size: int = 15000):\n",
    "    dataset = TimeseriesDataset(df)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=15, multiprocessing_context='fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pls.read_parquet(Path(data_path, \"train.parquet\", f\"partition_id={test_raw_data_num}\", \"part-0.parquet\"))\n",
    "data_loader = test_dataloader(test_data, batch_size=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 130/130 [00:03<00:00, 34.32it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   test_epoch_average       0.7978482246398926\n",
      "        test_loss           0.7976667284965515\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "test_results = trainer.test(model, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▂▆▂▆▇██▃▅▇▁▂▄▆▇▅▇█▂▂▆▆▁▂▇█▁▃▅▅▆▇▇▂▂▄▅▇▂▇</td></tr><tr><td>test_epoch_average</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>▃▃▃▄▄▅▆▆█████▅▆▅▆▄▄▄▄▄▄▃▄▄▃▄▃▂▂▁▃▃▄▁▁▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▂▂▂▁▁▂▂▃▃▄▄▁▁▁▃▂▃▅▅▅▆▅▅▅▆▄▄▅▅█▂▃▇█▁▃▄▄▅▇</td></tr><tr><td>training_epoch_average</td><td>▃▃▃▃▃▄▄▄▄▅█▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▁▁▁▃▃▃▃▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>25</td></tr><tr><td>test_epoch_average</td><td>0.79785</td></tr><tr><td>test_loss</td><td>0.79767</td></tr><tr><td>train_loss</td><td>0.66026</td></tr><tr><td>trainer/global_step</td><td>10475</td></tr><tr><td>training_epoch_average</td><td>0.6517</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">good-puddle-48</strong> at: <a href='https://wandb.ai/git-yang/jane_street/runs/d8utdrhm' target=\"_blank\">https://wandb.ai/git-yang/jane_street/runs/d8utdrhm</a><br/> View project at: <a href='https://wandb.ai/git-yang/jane_street' target=\"_blank\">https://wandb.ai/git-yang/jane_street</a><br/>Synced 5 W&B file(s), 0 media file(s), 502 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241223_210652-d8utdrhm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation using the given metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_weighted_zero_mean_r2(y_pred, y_truth, weight):\n",
    "    \"\"\"\n",
    "    Zero-mean R-squared metrics.\n",
    "\n",
    "    Args:\n",
    "        y_pred: Array of predicted values.\n",
    "        y_truth: Array of true values.\n",
    "        weight: Array of sample weights.\n",
    "\n",
    "    Returns:\n",
    "        1-corr: Zero-mean R-squared.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure weights are valid\n",
    "    weight = weight if weight is not None else np.ones_like(y_pred)\n",
    "    \n",
    "    corr = np.sum((weight * (y_truth - y_pred) ** 2)) / np.sum(weight * y_truth ** 2)\n",
    "    \n",
    "    return 1 - corr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_subset = test_data.select([col for col in test_data.columns if col in train_feature_list])\n",
    "test_data_subset = test_data_subset.fill_null(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(-0.045132518)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(torch.tensor(test_data_subset.to_numpy(), dtype=torch.float32)).squeeze().numpy()\n",
    "\n",
    "\n",
    "score = sample_weighted_zero_mean_r2(y_pred, test_data.select(pls.col(\"responder_6\")).to_numpy()[:,0],\n",
    "                                     test_data.select(pls.col(\"weight\")).to_numpy()[:,0])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
