{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jane Street Real-Time Market Data Forecasting baseline with LightGBM\n",
    "\n",
    "Link to the competition: https://www.kaggle.com/competitions/jane-street-real-time-market-data-forecasting/overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important information\n",
    "\n",
    "- Lags: Values of responder_{0...8} lagged by one date_id. The evaluation API serves the entirety of the lagged responders for a date_id on that date_id's first time_id. In other words, all of the previous date's responders will be served at the first time step of the succeeding date.\n",
    "\n",
    "- The symbol_id column contains encrypted identifiers. Each symbol_id is not guaranteed to appear in all time_id and date_id combinations. Additionally, new symbol_id values may appear in future test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we don't use lags at the moment. For more information about using lags data, check this [notebook](https://www.kaggle.com/code/motono0223/js24-preprocessing-create-lags)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the memory usage, we make use of the incremental training feature of lightgbm and feed model step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/yang/kaggle/jane/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each training set, we take 20% of the data for validation\n",
    "frac_train = 0.8\n",
    "train_raw_data_num = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "# a completely new dataset for testing\n",
    "test_raw_data_num = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_list = [\"time_id\", \"symbol_id\"] + [f\"feature_{idx:02d}\" for idx in range(79)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for LightGBM\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# initialize the model\n",
    "model = None\n",
    "\n",
    "evals_result = {}\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "for i in train_raw_data_num:\n",
    "    training_data = pl.read_parquet(Path(data_path, \"train.parquet\", f\"partition_id={i}\", \"part-0.parquet\"))\n",
    "    print(\"Size of training data (GB):\", training_data.estimated_size(\"gb\"))\n",
    "\n",
    "    #################################################################################################\n",
    "    ####################   Preprocess the training data and select features   #######################\n",
    "    #################################################################################################\n",
    "    training_data = training_data.fill_null(0)\n",
    "    training_data_subset = training_data.select([col for col in training_data.columns if col in train_feature_list])\n",
    "    #################################################################################################\n",
    "    label = training_data.select(pl.col(\"responder_6\"))\n",
    "    weight = training_data.select(pl.col(\"weight\"))\n",
    "    del training_data  # save memory\n",
    "    # Split the data into training and validation sets\n",
    "    split_index = int(frac_train * training_data_subset.shape[0])\n",
    "    training_data_loader = lgb.Dataset(training_data_subset[:split_index], label=label[:split_index].to_numpy(),\n",
    "                                       weight=weight[:split_index].to_numpy())\n",
    "    \n",
    "    validate_data_loader = lgb.Dataset(training_data_subset[split_index:], label=label[split_index:].to_numpy(),\n",
    "                                       reference=training_data_loader, weight=weight[split_index:].to_numpy())\n",
    "    \n",
    "    # Train the model\n",
    "    model = lgb.train(params, training_data_loader, init_model=model, num_boost_round=10,\n",
    "                      valid_sets=[training_data_loader, validate_data_loader],\n",
    "                      valid_names=['train', 'val'],\n",
    "                      callbacks=[lgb.early_stopping(stopping_rounds=5), lgb.record_evaluation(evals_result)],\n",
    "    )\n",
    "\n",
    "    # Access validation loss\n",
    "    training_loss.append(evals_result['train']['rmse'][-1])\n",
    "    validation_loss.append(evals_result['val']['rmse'][-1])\n",
    "    print(\"Training Losses per iteration:\", training_loss)\n",
    "    print(\"Validation Losses per iteration:\", validation_loss)\n",
    "\n",
    "model.save_model('jane_lgbm_null_to_0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot = {\"train\": training_loss,\n",
    "             \"validation\": validation_loss}\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data_plot)\n",
    "df[\"iterations\"] = range(len(df))\n",
    "df = pd.melt(df, id_vars=[\"iterations\"], var_name=\"set\", value_name=\"loss\")\n",
    "\n",
    "# Create a line chart\n",
    "fig = px.line(\n",
    "    df,\n",
    "    x=\"iterations\",\n",
    "    y=\"loss\",\n",
    "    color=\"set\",  # Each line is differentiated by color\n",
    "    title=\"Training and Validation Losses\",\n",
    "    labels={\"iterations\": \"iterations\", \"loss\": \"loss\"}\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pl.read_parquet(Path(data_path, \"train.parquet\", f\"partition_id={test_raw_data_num}\", \"part-0.parquet\"))\n",
    "test_data_subset = test_data.select([col for col in test_data.columns if col in train_feature_list])\n",
    "test_data.estimated_size(\"gb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved model to make predictions\n",
    "model = lgb.Booster(model_file='jane_lgbm_null_to_0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_data_subset)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_weighted_zero_mean_r2(y_pred, y_truth, weight):\n",
    "    \"\"\"\n",
    "    Zero-mean R-squared metrics.\n",
    "\n",
    "    Args:\n",
    "        y_pred: Array of predicted values.\n",
    "        y_truth: Array of true values.\n",
    "        weight: Array of sample weights.\n",
    "\n",
    "    Returns:\n",
    "        1-corr: Zero-mean R-squared.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure weights are valid\n",
    "    weight = weight if weight is not None else np.ones_like(y_pred)\n",
    "    \n",
    "    corr = np.sum((weight * (y_truth - y_pred) ** 2)) / np.sum(weight * y_truth ** 2)\n",
    "    \n",
    "    return 1 - corr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = sample_weighted_zero_mean_r2(y_pred, test_data.select(pl.col(\"responder_6\")).to_numpy()[:,0],\n",
    "                                     test_data.select(pl.col(\"weight\")).to_numpy()[:,0])\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
